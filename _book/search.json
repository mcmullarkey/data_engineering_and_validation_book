[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Engineering and Validation",
    "section": "",
    "text": "Or at least a systematic, repeatable process is absent↩︎\nSure, there are plenty of open source tools that enable data engineering + validation… and the most user-friendly ways to implement those tools are often in pay-to-use environments.↩︎\nLike Python and SQL↩︎\nLike Docker↩︎\nOr even less!↩︎\nInstead of having to download a file locally↩︎\nAt least to ~hundreds of thousands of rows↩︎\nThink acaedmic labs, non-profits, local governments, etc.↩︎\nThis book does not assume a computer science background↩︎"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "4  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "5  Summary",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "3  References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "00_building_first_pipeline.html",
    "href": "00_building_first_pipeline.html",
    "title": "1  Building Our First Pipeline",
    "section": "",
    "text": "A data pipeline has an unfortunate number of meanings. In this book we’re talking about a repeatable, scalable process for ingesting data so that end-users can use it. Let’s jump right into the building our first pipeline."
  },
  {
    "objectID": "00_building_first_pipeline.html#load-necessary-packages",
    "href": "00_building_first_pipeline.html#load-necessary-packages",
    "title": "1  Building Our First Pipeline",
    "section": "1.2 Load Necessary Packages",
    "text": "1.2 Load Necessary Packages\n\nlibrary(googlesheets4)\nlibrary(readr)\nlibrary(here)"
  },
  {
    "objectID": "00_building_first_pipeline.html#what-you-would-do-with-a-local-file",
    "href": "00_building_first_pipeline.html#what-you-would-do-with-a-local-file",
    "title": "1  Building Our First Pipeline",
    "section": "1.3 What You Would Do With a Local File",
    "text": "1.3 What You Would Do With a Local File\nIf we’re doing what small organizations often do, we download a .csv file from somewhere, stick it in the same folder as our code, and run read_csv() with the vague hope the data will read in correctly.\n\npenguins_local <- read_csv(\"palmer_penguins.csv\")\n\nThe aim of a data pipeline is to remove the manual steps like downloading the file and make the hope our data is correct more grounded in evidence."
  },
  {
    "objectID": "00_building_first_pipeline.html#what-you-do-with-a-remote-file-to-start-a-reproducible-pipeline",
    "href": "00_building_first_pipeline.html#what-you-do-with-a-remote-file-to-start-a-reproducible-pipeline",
    "title": "1  Building Our First Pipeline",
    "section": "1.4 What You Do With a Remote File to Start a Reproducible Pipeline",
    "text": "1.4 What You Do With a Remote File to Start a Reproducible Pipeline\n“Reading a remote file” can sound scary, but R can help make it as straightforward as reading in a local file. Using the googlesheets4 package, we’ll read in a remote file that contains the raw Palmer Penguins data.\n\n# Since this Google Sheet is public to anyone with the link we don't need\n# to authenticate\n\ngs4_deauth()\n\n# Get the URL of our Google Sheet\n\nurl <- \"https://docs.google.com/spreadsheets/d/1v0lG-4arxF_zCCpfoUzCydwzaea7QqWTTQzTr8Dompw/edit?usp=sharing\"\n\n# Read in the penguins data using the googlesheets4 package\n\npenguins_remote <- read_sheet(url)\n\nAnd we’ve kicked off our pipeline! We’ll focus on reading remotely from Google Sheets in this textbook since everyone will be able to access it for learning purposes. See this footnote for R packages that can help you read in your data from other sources.1"
  },
  {
    "objectID": "00_building_first_pipeline.html#only-one-more-step-to-complete-a-minimal-reproducible-pipeline",
    "href": "00_building_first_pipeline.html#only-one-more-step-to-complete-a-minimal-reproducible-pipeline",
    "title": "1  Building Our First Pipeline",
    "section": "1.5 Only One More Step to Complete a Minimal, Reproducible Pipeline",
    "text": "1.5 Only One More Step to Complete a Minimal, Reproducible Pipeline\nThe final step of our minimal pipeline is writing the data to a location where end-users can access it. In this case we’ll write the raw Palmer Penguins data to the “raw” folder in our R Project.2 We use the here package to make sure we don’t lose track of our files.3\n\noutput_path <- here::here(\"data_from_gsheets/raw/palmer_penguins.csv\")\n\nwrite_csv(penguins_remote, output_path)\n\nAnd our first, minimal data pipeline is complete! We’ve created a process where we could open an R Project, run a script, and have an updated version of our data available to end-users. We’re just getting started, and in the next chapter we’ll make some much needed upgrades to this minimal pipeline."
  },
  {
    "objectID": "01_initial_pipeline_upgrades.html",
    "href": "01_initial_pipeline_upgrades.html",
    "title": "2  Initial Pipeline Upgrades",
    "section": "",
    "text": "library(googlesheets4)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\nlibrary(pointblank)"
  },
  {
    "objectID": "01_initial_pipeline_upgrades.html#we-can-improve-how-we-call-the-sheet",
    "href": "01_initial_pipeline_upgrades.html#we-can-improve-how-we-call-the-sheet",
    "title": "2  Initial Pipeline Upgrades",
    "section": "2.2 We Can Improve How We Call The Sheet",
    "text": "2.2 We Can Improve How We Call The Sheet\n\n# Since this Google Sheet is public to anyone with the link we don't need\n# to authenticate\n\ngs4_deauth()\n\n# Get the ID of our Google Sheet\n\nsheet_id <- \"1v0lG-4arxF_zCCpfoUzCydwzaea7QqWTTQzTr8Dompw\"\n\n# Read in the penguins data using the googlesheets4 package\n\npenguins_remote_improved <- read_sheet(sheet_id)"
  },
  {
    "objectID": "01_initial_pipeline_upgrades.html#lets-scan-our-data-for-any-obvious-problems",
    "href": "01_initial_pipeline_upgrades.html#lets-scan-our-data-for-any-obvious-problems",
    "title": "2  Initial Pipeline Upgrades",
    "section": "2.5 Let’s Scan Our Data for Any Obvious Problems",
    "text": "2.5 Let’s Scan Our Data for Any Obvious Problems\nNow that we’ve made our variable names easier to work with let’s dive into the actual data. The scan_data() function from the {pointblank} package in R makes it easy to get a high level overview of our data. I want the ten-thousand foot view first, so let’s look at just the overview of our data frame.\n\nscan_data(penguins_improved_initial, sections = \"O\")\n\n\n\n\n\n        \n    \n    \n  \n\n\n\n\n\n\nOverview of penguins_improved_initial\n\n\n\n\n\nOverview\n\n\nReproducibility\n\n\n\n\n\nTable Overview\n\n\n\n  \n  \n    Columns\n\n17\n    Rows\n\n344\n    NAs\n\n2,365 (40.44%)\n    Duplicate Rows\n\n0\n  \n  \n  \n\n\n\n\nColumn Types\n\n\n\n  \n  \n    character\n9\n    logical\n6\n    POSIXct\n1\n    numeric\n1\n  \n  \n  \n\n\n\n\n\n\nReproducibility Information\n\n\n\n  \n  \n    Scan Build Time\n\n2023-09-26 11:48:17\n\n    pointblank Version\n\n0.11.4\n\n    R Version\n\nR version 4.1.3 (2022–03–10)One Push–Up\n\n    Operating System\n\nx86_64-apple-darwin17.0\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\nTable scan generated with pointblank."
  },
  {
    "objectID": "01_initial_pipeline_upgrades.html#oh-my-god-where-did-so-much-of-our-data-go",
    "href": "01_initial_pipeline_upgrades.html#oh-my-god-where-did-so-much-of-our-data-go",
    "title": "2  Initial Pipeline Upgrades",
    "section": "2.6 Oh My God Where Did So Much of Our Data Go??",
    "text": "2.6 Oh My God Where Did So Much of Our Data Go??\nOver 40% of our data is missing, which seems like a bad sign. The scan_data() function can help us see where this data is missing quickly with a handy visualization.\n\nscan_data(penguins_improved_initial, sections = \"M\")\n\n\n\n\n\n        \n    \n    \n  \n\n\n\n\n\n\nMissing Values\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable scan generated with pointblank.\n\n\n\n\n\n\n\n\n\nOkay, so we’ve already narrowed our problem down to a certain set of columns where the data seems to be almost entirely missing. Maybe it’s on purpose and we’re fine?\n\npenguins_remote_improved %>% \n  clean_names() %>% \n  select(c(culmen_length_mm:body_mass_g,delta_15_n_o_oo,delta_13_c_o_oo))\n\n# A tibble: 344 × 6\n   culmen_length_mm culmen_depth_mm flipper_length_mm body_mass_g\n   <list>           <list>          <list>            <list>     \n 1 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 2 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 3 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 4 <chr [1]>        <chr [1]>       <chr [1]>         <chr [1]>  \n 5 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 6 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 7 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 8 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 9 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n10 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n# ℹ 334 more rows\n# ℹ 2 more variables: delta_15_n_o_oo <list>, delta_13_c_o_oo <list>\n\n\nNot quite. Most of the “missing” data are hiding in list-columns, a column type in R that can contain a whole list within each row. So the data isn’t so much “missing” as “inaccessible in its current format.”\nThis list-column property can be useful in certain cases, but it wasn’t what we were going for here. What do we do now?"
  },
  {
    "objectID": "01_initial_pipeline_upgrades.html#data-engineering-is-about-tradeoffs-procedures",
    "href": "01_initial_pipeline_upgrades.html#data-engineering-is-about-tradeoffs-procedures",
    "title": "2  Initial Pipeline Upgrades",
    "section": "2.7 Data Engineering is About Tradeoffs + Procedures",
    "text": "2.7 Data Engineering is About Tradeoffs + Procedures\nOne rule we’ve likely all heard is to never touch “raw” data. However, in a data engineering role the “raw” data can be completely unusable, nonsensical, or worse.\nHaving a reproducible pipeline with automated checks for data quality can help, and there’s still a human3 making these decisions.\nTherefore, while it’s good practice to not edit “raw” data files once they’re established we still want the “raw” data to contain the information we need. Let’s figure out how to rescuse the information out of those list-columns.\nSince I happen to know these values are “nested” in lists maybe we can access them by using the unnest() function. Let’s try that on the offending columns.\n\npenguins_remote_improved %>%\n  clean_names() %>%\n  unnest(c(culmen_length_mm:body_mass_g,delta_15_n_o_oo,delta_13_c_o_oo))\n\nError in `list_unchop()`:\n! Can't combine `x[[1]]` <double> and `x[[4]]` <character>."
  },
  {
    "objectID": "01_initial_pipeline_upgrades.html#are-we-doomed",
    "href": "01_initial_pipeline_upgrades.html#are-we-doomed",
    "title": "2  Initial Pipeline Upgrades",
    "section": "2.8 Are We Doomed?",
    "text": "2.8 Are We Doomed?\nNope! Errors are an inevitable part of improving a pipeline. Also, if you’re not finding anything weird with your pipeline I’d be more nervous than if you find errors like this one.\nIn this case, we see there are values of multiple types4 in a column that can’t be combined. I have a hunch based on experience, which I can investigate further by looking at the “sex” column.\n\npenguins_remote_improved %>% \n  clean_names() %>% \n  count(sex)\n\n# A tibble: 3 × 2\n  sex        n\n  <chr>  <int>\n1 FEMALE   165\n2 MALE     168\n3 NA        11\n\n\nAha! It looks like the value “NA” is getting read as a character variable rather than a missing value. This could be what’s going on with our initial read using read_sheet() Let’s investigate.\n\npenguins_na_fix <- read_sheet(sheet_id, na = \"NA\")\n\npenguins_na_fix %>% \n  clean_names() %>% \n  select(c(culmen_length_mm:body_mass_g,delta_15_n_o_oo,delta_13_c_o_oo))\n\n# A tibble: 344 × 6\n   culmen_length_mm culmen_depth_mm flipper_length_mm body_mass_g\n              <dbl>           <dbl>             <dbl>       <dbl>\n 1             39.1            18.7               181        3750\n 2             39.5            17.4               186        3800\n 3             40.3            18                 195        3250\n 4             NA              NA                  NA          NA\n 5             36.7            19.3               193        3450\n 6             39.3            20.6               190        3650\n 7             38.9            17.8               181        3625\n 8             39.2            19.6               195        4675\n 9             34.1            18.1               193        3475\n10             42              20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: delta_15_n_o_oo <dbl>, delta_13_c_o_oo <dbl>\n\n\nFantastic, the information from these columns seems to be available to us now. Let’s check the overall dataframe using scan data again, this time with the overview + missingness plot generated simultaneously.\n\nscan_data(penguins_na_fix, sections = \"OM\")\n\n\n\n\n\n        \n    \n    \n  \n\n\n\n\n\n\nOverview of penguins_na_fix\n\n\n\n\n\nOverview\n\n\nReproducibility\n\n\n\n\n\nTable Overview\n\n\n\n  \n  \n    Columns\n\n17\n    Rows\n\n344\n    NAs\n\n336 (5.75%)\n    Duplicate Rows\n\n0\n  \n  \n  \n\n\n\n\nColumn Types\n\n\n\n  \n  \n    character\n9\n    numeric\n7\n    POSIXct\n1\n  \n  \n  \n\n\n\n\n\n\nReproducibility Information\n\n\n\n  \n  \n    Scan Build Time\n\n2023-09-26 16:19:32\n\n    pointblank Version\n\n0.11.4\n\n    R Version\n\nR version 4.1.3 (2022–03–10)One Push–Up\n\n    Operating System\n\nx86_64-apple-darwin17.0\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\nMissing Values\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable scan generated with pointblank.\n\n\n\n\n\n\n\n\n\nDown to ~6% missing data! Most of that missingness seems concentrated in the “comments” column, which we can take a quick peek at.\n\npenguins_na_fix %>% \n  clean_names() %>% \n  select(comments)\n\n# A tibble: 344 × 1\n   comments                             \n   <chr>                                \n 1 Not enough blood for isotopes.       \n 2 <NA>                                 \n 3 <NA>                                 \n 4 Adult not sampled.                   \n 5 <NA>                                 \n 6 <NA>                                 \n 7 Nest never observed with full clutch.\n 8 Nest never observed with full clutch.\n 9 No blood sample obtained.            \n10 No blood sample obtained for sexing. \n# ℹ 334 more rows\n\n\nBased on our investigation and the Palmer Penguins documentation this data is looking much more like the data we’d expect."
  },
  {
    "objectID": "01_initial_pipeline_upgrades.html#still-read-in-raw-data-at-first",
    "href": "01_initial_pipeline_upgrades.html#still-read-in-raw-data-at-first",
    "title": "2  Initial Pipeline Upgrades",
    "section": "2.3 Still Read in Raw Data at First",
    "text": "2.3 Still Read in Raw Data at First\nWe’ll continue our pipeline as in the last chapter by writing our just ingested data to the “raw/” folder in our R Project.\n\noutput_path_improved <- here::here(\"data_from_gsheets/raw/palmer_penguins_improved.csv\")\n\nwrite_csv(penguins_remote_improved, output_path_improved)"
  },
  {
    "objectID": "01_initial_pipeline_upgrades.html#add-some-pre-processing-to-our-pipeline",
    "href": "01_initial_pipeline_upgrades.html#add-some-pre-processing-to-our-pipeline",
    "title": "2  Initial Pipeline Upgrades",
    "section": "2.4 Add Some Pre-Processing to Our Pipeline",
    "text": "2.4 Add Some Pre-Processing to Our Pipeline\nLet’s start by using the {janitor} package to clean up our column names. This will make it easier to work with the data moving forward.\nA big part of data engineering is naming things consistently and choosing how to format your variables. Naming things sounds simple but is notoriously difficult.\nKeeping names simple, avoiding ambiguity where possible, and using a consistent structure for names can all help. The {janitor} package helps us enforce a consistent structure for our variables in one line of code.\n\npenguins_improved_initial <- \n  read_csv(\"data_from_gsheets/raw/palmer_penguins_improved.csv\") %>% \n  clean_names()\n\nIn the raw Palmer Penguins data the variable names’ structure is all over the place. “studyName” uses camel case, there’s inconsistent capitalization across names, special characters like “(” that can cause issues on some systems, and there are often spaces.1\n\npenguins_remote_improved %>% \n  names()\n\n [1] \"studyName\"           \"Sample Number\"       \"Species\"            \n [4] \"Region\"              \"Island\"              \"Stage\"              \n [7] \"Individual ID\"       \"Clutch Completion\"   \"Date Egg\"           \n[10] \"Culmen Length (mm)\"  \"Culmen Depth (mm)\"   \"Flipper Length (mm)\"\n[13] \"Body Mass (g)\"       \"Sex\"                 \"Delta 15 N (o/oo)\"  \n[16] \"Delta 13 C (o/oo)\"   \"Comments\"           \n\n\nAfter running clean_names() we get consistent “snake case”2 separation for words, consistent lower-case for all characters, no special characters like “(” and no spaces. This standardization makes it easier to remember, type, and reuse these variable names. Enforce a standard like this for your data and your end-users will thank you.\n\npenguins_improved_initial %>% \n  names()\n\n [1] \"study_name\"        \"sample_number\"     \"species\"          \n [4] \"region\"            \"island\"            \"stage\"            \n [7] \"individual_id\"     \"clutch_completion\" \"date_egg\"         \n[10] \"culmen_length_mm\"  \"culmen_depth_mm\"   \"flipper_length_mm\"\n[13] \"body_mass_g\"       \"sex\"               \"delta_15_n_o_oo\"  \n[16] \"delta_13_c_o_oo\"   \"comments\""
  },
  {
    "objectID": "01_initial_pipeline_upgrades.html#an-already-improved-pipeline",
    "href": "01_initial_pipeline_upgrades.html#an-already-improved-pipeline",
    "title": "2  Initial Pipeline Upgrades",
    "section": "2.9 An Already Improved Pipeline",
    "text": "2.9 An Already Improved Pipeline\nWe have a much better pipeline than we did just a chapter ago!\nHow did I know about the na argument inside of read_sheet()? I looked at the documentation! Also, as you develop better instincts you can press Ctrl + Spacebar to see what parameters like na are available inside of a function like read_sheet().\nLet’s read this version with our NA fix into the folder so we can continue to upgrade our pipeline. We’re going to overwrite the previous, non-useful version of the file. However, we need to be careful when building pipelines that we only overwrite files when we mean to!\n\noutput_path_nafix <- here::here(\"data_from_gsheets/raw/palmer_penguins_improved.csv\")\n\nwrite_csv(penguins_na_fix, output_path_nafix)"
  },
  {
    "objectID": "01_initial_pipeline_upgrades.html#improve-how-we-call-the-sheet",
    "href": "01_initial_pipeline_upgrades.html#improve-how-we-call-the-sheet",
    "title": "2  Initial Pipeline Upgrades",
    "section": "2.2 Improve How We Call The Sheet",
    "text": "2.2 Improve How We Call The Sheet\nImproving our pipeline means looking for ways, big and small, to improve our code.\nWe get an opportunity right off the bat! Rather than copy/pasting the entire URL we can just take the sheet ID of of our Google Sheet. Getting the same information with less keystrokes and opportunity for error is always a win.\n\n# Since this Google Sheet is public to anyone with the link we don't need\n# to authenticate\n\ngs4_deauth()\n\n# Get the ID of our Google Sheet\n\nsheet_id <- \"1v0lG-4arxF_zCCpfoUzCydwzaea7QqWTTQzTr8Dompw\"\n\n# Read in the penguins data using the googlesheets4 package\n\npenguins_remote_improved <- read_sheet(sheet_id)"
  },
  {
    "objectID": "00_building_first_pipeline.html#load-packages",
    "href": "00_building_first_pipeline.html#load-packages",
    "title": "1  Building Our First Pipeline",
    "section": "1.2 Load Packages",
    "text": "1.2 Load Packages\n\nlibrary(googlesheets4)\nlibrary(readr)\nlibrary(here)"
  },
  {
    "objectID": "01_initial_pipeline_upgrades.html#add-some-pre-processing",
    "href": "01_initial_pipeline_upgrades.html#add-some-pre-processing",
    "title": "2  Initial Pipeline Upgrades",
    "section": "2.4 Add Some Pre-Processing",
    "text": "2.4 Add Some Pre-Processing\nLet’s start by using the {janitor} package to clean up our column names. This will make it easier to work with the data moving forward.\nA big part of data engineering is naming things consistently and choosing how to format your variables. Naming things sounds simple but is notoriously difficult.\nKeeping names simple, avoiding ambiguity where possible, and using a consistent structure for names can all help. The {janitor} package helps us enforce a consistent structure for our variables in one line of code.\n\npenguins_improved_initial <- \n  read_csv(\"data_from_gsheets/raw/palmer_penguins_improved.csv\") %>% \n  clean_names()\n\nIn the raw Palmer Penguins data the variable names’ structure is all over the place. “studyName” uses camel case, there’s inconsistent capitalization across names, special characters like “(” that can cause issues on some systems, and there are often spaces.1\n\npenguins_remote_improved %>% \n  names()\n\n [1] \"studyName\"           \"Sample Number\"       \"Species\"            \n [4] \"Region\"              \"Island\"              \"Stage\"              \n [7] \"Individual ID\"       \"Clutch Completion\"   \"Date Egg\"           \n[10] \"Culmen Length (mm)\"  \"Culmen Depth (mm)\"   \"Flipper Length (mm)\"\n[13] \"Body Mass (g)\"       \"Sex\"                 \"Delta 15 N (o/oo)\"  \n[16] \"Delta 13 C (o/oo)\"   \"Comments\"           \n\n\nAfter running clean_names() we get consistent “snake case”2 separation for words, consistent lower-case for all characters, no special characters like “(” and no spaces. This standardization makes it easier to remember, type, and reuse these variable names. Enforce a standard like this for your data and your end-users will thank you.\n\npenguins_improved_initial %>% \n  names()\n\n [1] \"study_name\"        \"sample_number\"     \"species\"          \n [4] \"region\"            \"island\"            \"stage\"            \n [7] \"individual_id\"     \"clutch_completion\" \"date_egg\"         \n[10] \"culmen_length_mm\"  \"culmen_depth_mm\"   \"flipper_length_mm\"\n[13] \"body_mass_g\"       \"sex\"               \"delta_15_n_o_oo\"  \n[16] \"delta_13_c_o_oo\"   \"comments\""
  },
  {
    "objectID": "01_initial_pipeline_upgrades.html#scanning-our-data-for-problems",
    "href": "01_initial_pipeline_upgrades.html#scanning-our-data-for-problems",
    "title": "2  Initial Pipeline Upgrades",
    "section": "2.5 Scanning Our Data for Problems",
    "text": "2.5 Scanning Our Data for Problems\nNow that we’ve made our variable names easier to work with let’s dive into the actual data. The scan_data() function from the {pointblank} package in R makes it easy to get a high level overview of our data. I want the ten-thousand foot view first, so let’s look at just the overview of our data frame.\n\nscan_data(penguins_improved_initial, sections = \"O\")\n\n\n\n\n\n        \n    \n    \n  \n\n\n\n\n\n\nOverview of penguins_improved_initial\n\n\n\n\n\nOverview\n\n\nReproducibility\n\n\n\n\n\nTable Overview\n\n\n\n  \n  \n    Columns\n\n17\n    Rows\n\n344\n    NAs\n\n2,365 (40.44%)\n    Duplicate Rows\n\n0\n  \n  \n  \n\n\n\n\nColumn Types\n\n\n\n  \n  \n    character\n9\n    logical\n6\n    POSIXct\n1\n    numeric\n1\n  \n  \n  \n\n\n\n\n\n\nReproducibility Information\n\n\n\n  \n  \n    Scan Build Time\n\n2023-09-26 16:19:29\n\n    pointblank Version\n\n0.11.4\n\n    R Version\n\nR version 4.1.3 (2022–03–10)One Push–Up\n\n    Operating System\n\nx86_64-apple-darwin17.0\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\nTable scan generated with pointblank."
  },
  {
    "objectID": "01_initial_pipeline_upgrades.html#where-did-so-much-of-our-data-go",
    "href": "01_initial_pipeline_upgrades.html#where-did-so-much-of-our-data-go",
    "title": "2  Initial Pipeline Upgrades",
    "section": "2.6 Where Did So Much of Our Data Go??",
    "text": "2.6 Where Did So Much of Our Data Go??\nOver 40% of our data is missing, which seems like a bad sign. The scan_data() function can help us see where this data is missing quickly with a handy visualization.\n\nscan_data(penguins_improved_initial, sections = \"M\")\n\n\n\n\n\n        \n    \n    \n  \n\n\n\n\n\n\nMissing Values\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable scan generated with pointblank.\n\n\n\n\n\n\n\n\n\nOkay, so we’ve already narrowed our problem down to a certain set of columns where the data seems to be almost entirely missing. Maybe it’s on purpose and we’re fine?\n\npenguins_remote_improved %>% \n  clean_names() %>% \n  select(c(culmen_length_mm:body_mass_g,delta_15_n_o_oo,delta_13_c_o_oo))\n\n# A tibble: 344 × 6\n   culmen_length_mm culmen_depth_mm flipper_length_mm body_mass_g\n   <list>           <list>          <list>            <list>     \n 1 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 2 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 3 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 4 <chr [1]>        <chr [1]>       <chr [1]>         <chr [1]>  \n 5 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 6 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 7 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 8 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 9 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n10 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n# ℹ 334 more rows\n# ℹ 2 more variables: delta_15_n_o_oo <list>, delta_13_c_o_oo <list>\n\n\nNot quite. Most of the “missing” data are hiding in list-columns, a column type in R that can contain a whole list within each row. So the data isn’t so much “missing” as “inaccessible in its current format.”\nThis list-column property can be useful in certain cases, but it wasn’t what we were going for here. What do we do now?"
  },
  {
    "objectID": "01_initial_pipeline_upgrades.html#where-did-our-data-go",
    "href": "01_initial_pipeline_upgrades.html#where-did-our-data-go",
    "title": "2  Initial Pipeline Upgrades",
    "section": "2.6 Where Did Our Data Go??",
    "text": "2.6 Where Did Our Data Go??\nOver 40% of our data is missing, which seems like a bad sign. The scan_data() function can help us see where this data is missing quickly with a handy visualization.\n\nscan_data(penguins_improved_initial, sections = \"M\")\n\n\n\n\n\n        \n    \n    \n  \n\n\n\n\n\n\nMissing Values\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable scan generated with pointblank.\n\n\n\n\n\n\n\n\n\nOkay, so we’ve already narrowed our problem down to a certain set of columns where the data seems to be almost entirely missing. Maybe it’s on purpose and we’re fine?\n\npenguins_remote_improved %>% \n  clean_names() %>% \n  select(c(culmen_length_mm:body_mass_g,delta_15_n_o_oo,delta_13_c_o_oo))\n\n# A tibble: 344 × 6\n   culmen_length_mm culmen_depth_mm flipper_length_mm body_mass_g\n   <list>           <list>          <list>            <list>     \n 1 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 2 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 3 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 4 <chr [1]>        <chr [1]>       <chr [1]>         <chr [1]>  \n 5 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 6 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 7 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 8 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n 9 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n10 <dbl [1]>        <dbl [1]>       <dbl [1]>         <dbl [1]>  \n# ℹ 334 more rows\n# ℹ 2 more variables: delta_15_n_o_oo <list>, delta_13_c_o_oo <list>\n\n\nNot quite. Most of the “missing” data are hiding in list-columns, a column type in R that can contain a whole list within each row. So the data isn’t so much “missing” as “inaccessible in its current format.”\nThis list-column property can be useful in certain cases, but it wasn’t what we were going for here. What do we do now?"
  },
  {
    "objectID": "02_add_automated_test.html",
    "href": "02_add_automated_test.html",
    "title": "3  Add an Automated Test",
    "section": "",
    "text": "Let’s run back through our pipeline and make some further improvements. Yes, it will involve learning what an automated test is and why you’ll learn to love them!"
  },
  {
    "objectID": "02_add_automated_test.html#add-pre-processing-redux",
    "href": "02_add_automated_test.html#add-pre-processing-redux",
    "title": "3  Add an Automated Test",
    "section": "3.3 Add Pre-Processing, Redux",
    "text": "3.3 Add Pre-Processing, Redux\nLet’s start by using the {janitor} package to clean up our column names. This will make it easier to work with the data moving forward.\nYou’ll notice I had to call the clean_names() function many times in the previous chapter, which we want to avoid. Ideally we copy and paste as little as possible while writing code.\n\npenguins_improved_redux <- \n  read_csv(\"data_from_gsheets/raw/palmer_penguins_improved.csv\") %>% \n  clean_names()"
  },
  {
    "objectID": "02_add_automated_test.html#first-level-of-the-plan-is-tidy-data",
    "href": "02_add_automated_test.html#first-level-of-the-plan-is-tidy-data",
    "title": "3  Add an Automated Test",
    "section": "5.1 First Level of the Plan is Tidy Data",
    "text": "5.1 First Level of the Plan is Tidy Data"
  },
  {
    "objectID": "02_add_automated_test.html#deeper-levels-of-the-plan-depend-on-your-data-context",
    "href": "02_add_automated_test.html#deeper-levels-of-the-plan-depend-on-your-data-context",
    "title": "3  Add an Automated Test",
    "section": "5.2 Deeper Levels of the Plan Depend on Your Data + Context",
    "text": "5.2 Deeper Levels of the Plan Depend on Your Data + Context"
  },
  {
    "objectID": "02_add_automated_test.html#even-what-tidy-data-means-depends-on-your-needs",
    "href": "02_add_automated_test.html#even-what-tidy-data-means-depends-on-your-needs",
    "title": "3  Add an Automated Test",
    "section": "5.3 Even What Tidy Data Means Depends on Your Needs",
    "text": "5.3 Even What Tidy Data Means Depends on Your Needs"
  },
  {
    "objectID": "02_add_automated_test.html#we-need-a-plan",
    "href": "02_add_automated_test.html#we-need-a-plan",
    "title": "3  Add an Automated Test",
    "section": "3.4 We Need a Plan",
    "text": "3.4 We Need a Plan\n\n3.4.1 First Level of the Plan is Tidy Data\n\n\n3.4.2 Deeper Levels of the Plan Depend on Your Data + Context\n\n\n3.4.3 Even What Tidy Data Means Depends on Your Needs"
  },
  {
    "objectID": "02_add_automated_test.html#convert-plans-into-code",
    "href": "02_add_automated_test.html#convert-plans-into-code",
    "title": "3  Add an Automated Test",
    "section": "3.6 Convert Plans Into Code",
    "text": "3.6 Convert Plans Into Code\nLet’s say our definition of tidy data is only one sample per penguin. We also know1 that we only want the last sample collected from each penguin. We can express that with code here\n\npenguins_unique_sample <- penguins_improved_redux %>%\n  arrange(desc(date_egg)) %>% \n  distinct(individual_id, .keep_all = TRUE)"
  },
  {
    "objectID": "02_add_automated_test.html#we-cant-just-assume-our-plans-will-work",
    "href": "02_add_automated_test.html#we-cant-just-assume-our-plans-will-work",
    "title": "3  Add an Automated Test",
    "section": "3.6 We Can’t Just Assume Our Plans Will Work",
    "text": "3.6 We Can’t Just Assume Our Plans Will Work\nIf the above code is executed well we should get what we want. But we should check behind ourselves!\nWe tend to do this in an ad hoc way in our code. The most common way is to see if the code runs at all. If it doesn’t we can safely assume we failed. The next most common is just printing out output and seeing if it looks ok.\nThese are understandable approaches, and we can do better"
  },
  {
    "objectID": "02_add_automated_test.html#automatically-check-if-our-plans-worked",
    "href": "02_add_automated_test.html#automatically-check-if-our-plans-worked",
    "title": "3  Add an Automated Test",
    "section": "3.7 Automatically Check If Our Plans Worked",
    "text": "3.7 Automatically Check If Our Plans Worked\nLuckily the the {pointblank} package is way more than the scan_data() function we used in the last chapter. It’s an entire ecosystem for checking our data more thoroughly, creating reports, and even emailing those reports automatically.\nYou can find more info at the package’s docs or this Youtube video with demonstrations. We can demonstrate its functionality here by checking to make sure each individual_id in our penguins data is unique now.\n\n# Create a pointblank `agent` object, with the\n# penguins_unique_sample as the target table. Use one validation\n# functions, then, `interrogate()`. The agent will\n# then have some useful intel.\n\npenguins_distinct_agent <- \n  penguins_unique_sample %>%\n  create_agent(\n    label = \"Check for unique penguin ids\",\n    actions = action_levels(warn_at = 1)\n  ) %>%\n  rows_distinct(\n    vars(individual_id)\n  ) %>%\n  interrogate()"
  },
  {
    "objectID": "02_add_automated_test.html#making-the-results-of-our-automatic-tests-visible",
    "href": "02_add_automated_test.html#making-the-results-of-our-automatic-tests-visible",
    "title": "3  Add an Automated Test",
    "section": "3.9 Making The Results of Our Automatic Tests Visible",
    "text": "3.9 Making The Results of Our Automatic Tests Visible\nWe want to be able to figure out if our tests passed or failed easily. If something’s wrong with the data, we want our process to “fail” loudly and in a way we can see! That loud “failure” is a success in data engineering because we’ve prevented contaminiated data from infecting the rest of our process.\nLuckily {pointblank} gives us easy to understand reports when we call an agent object like penguins_distinct_agent. The “warning” circle isn’t filled in under “W” which means our automated test has passed!\n\npenguins_distinct_agent\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n      Pointblank Validation\n    \n    \n      Check for unique penguin ids\ntibbleWARN\n1\nSTOP\n—\nNOTIFY\n—\n\n    \n    \n      \n      \n      STEP\n      COLUMNS\n      VALUES\n      TBL\n      EVAL\n      UNITS\n      PASS\n      FAIL\n      W\n      S\n      N\n      EXT\n    \n  \n  \n    \n1\n\n      rows_distinct                                                                                                            \n   rows_distinct()\n\n\n\n  \n    ▮individual_id\n  \n\n\n—\n                                                            \n\n✓\n\n190\n1901.00\n00.00\n○\n\n—\n\n—\n\n—\n\n  \n  \n    \n      2023-09-26 14:55:23 MDT\n< 1 s\n2023-09-26 14:55:23 MDT"
  },
  {
    "objectID": "02_add_automated_test.html#we-will-never-have-100-converage-with-automatic-tests",
    "href": "02_add_automated_test.html#we-will-never-have-100-converage-with-automatic-tests",
    "title": "3  Add an Automated Test",
    "section": "3.10 We Will Never Have 100% Converage with Automatic Tests",
    "text": "3.10 We Will Never Have 100% Converage with Automatic Tests\nWhich tests we create are human, scientific issues that we enshrine in code. For example, I didn’t include any kind of check here to see if we for sure got the most recent sample from each penguin.\nSince this is for demonstration purposes, that’s fine. If it’s crucial for our research questions of interest that only the most recent sample be used, we should build a check for that too.\nEvery decision we make is a trade-off. So while we won’t get 100% coverage with these automatic tests, we should prioritize testing things that would catastrophically impact our data."
  },
  {
    "objectID": "02_add_automated_test.html#finishing-the-pipeline-by-writing-the-new-dataset-to-processed-data",
    "href": "02_add_automated_test.html#finishing-the-pipeline-by-writing-the-new-dataset-to-processed-data",
    "title": "3  Add an Automated Test",
    "section": "3.9 Finishing the Pipeline by Writing the New Dataset to Processed Data",
    "text": "3.9 Finishing the Pipeline by Writing the New Dataset to Processed Data\n\noutput_path_processed <- here::here(\"data_from_gsheets/processed/palmer_penguins_improved.csv\")\n\nwrite_csv(penguins_unique_sample, output_path_processed)"
  },
  {
    "objectID": "00_building_first_pipeline.html#starting-a-reproducible-pipeline",
    "href": "00_building_first_pipeline.html#starting-a-reproducible-pipeline",
    "title": "1  Building Our First Pipeline",
    "section": "1.4 Starting a Reproducible Pipeline",
    "text": "1.4 Starting a Reproducible Pipeline\n“Reading a remote file” can sound scary, but R can help make it as straightforward as reading in a local file. Using the googlesheets4 package, we’ll read in a remote file that contains the raw Palmer Penguins data.\n\n# Since this Google Sheet is public to anyone with the link we don't need\n# to authenticate\n\ngs4_deauth()\n\n# Get the URL of our Google Sheet\n\nurl <- \"https://docs.google.com/spreadsheets/d/1v0lG-4arxF_zCCpfoUzCydwzaea7QqWTTQzTr8Dompw/edit?usp=sharing\"\n\n# Read in the penguins data using the googlesheets4 package\n\npenguins_remote <- read_sheet(url)\n\nAnd we’ve kicked off our pipeline! We’ll focus on reading remotely from Google Sheets in this textbook since everyone will be able to access it for learning purposes. See this footnote for R packages that can help you read in your data from other sources.1"
  },
  {
    "objectID": "01_initial_pipeline_upgrades.html#load-packages",
    "href": "01_initial_pipeline_upgrades.html#load-packages",
    "title": "2  Initial Pipeline Upgrades",
    "section": "2.2 Load Packages",
    "text": "2.2 Load Packages\n\nlibrary(googlesheets4)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\nlibrary(pointblank)"
  },
  {
    "objectID": "02_add_automated_test.html#load-packages",
    "href": "02_add_automated_test.html#load-packages",
    "title": "3  Add an Automated Test",
    "section": "3.2 Load Packages",
    "text": "3.2 Load Packages\n\nlibrary(googlesheets4)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\nlibrary(pointblank)\nlibrary(lubridate)\nlibrary(glue)"
  },
  {
    "objectID": "02_add_automated_test.html#we-cant-assume-our-plans-will-work",
    "href": "02_add_automated_test.html#we-cant-assume-our-plans-will-work",
    "title": "3  Add an Automated Test",
    "section": "3.7 We Can’t Assume Our Plans Will Work",
    "text": "3.7 We Can’t Assume Our Plans Will Work\nIf the above code is executed well we should get what we want, and we should check behind ourselves!\nWe tend to do this in an ad-hoc way in our code. The most common way is to see if the code runs at all. If it doesn’t we can safely assume we failed. The next most common is just printing out output and seeing if it looks ok.\nThese are understandable approaches, and we can do better"
  },
  {
    "objectID": "02_add_automated_test.html#lets-automatically-check-if-our-plans-worked",
    "href": "02_add_automated_test.html#lets-automatically-check-if-our-plans-worked",
    "title": "3  Add an Automated Test",
    "section": "3.8 Let’s Automatically Check If Our Plans Worked",
    "text": "3.8 Let’s Automatically Check If Our Plans Worked\nLuckily the the {pointblank} package is way more than the scan_data() function we used in the last chapter. It’s an entire ecosystem for checking our data more thoroughly, creating reports, and even emailing those reports automatically.\nYou can find more info at the package’s docs or this Youtube video with demonstrations. We can demonstrate its functionality here by checking to make sure each individual_id in our penguins data is unique now.\n\n# Create a pointblank `agent` object, with the\n# penguins_unique_sample as the target table. Use one validation\n# functions, then, `interrogate()`. The agent will\n# then have some useful intel.\n\npenguins_distinct_agent <- \n  penguins_unique_sample %>%\n  create_agent(\n    label = \"Check for unique penguin ids\",\n    actions = action_levels(warn_at = 1)\n  ) %>%\n  rows_distinct(\n    vars(individual_id)\n  ) %>%\n  interrogate()"
  },
  {
    "objectID": "02_add_automated_test.html#stop-coidng",
    "href": "02_add_automated_test.html#stop-coidng",
    "title": "3  Add an Automated Test",
    "section": "3.4 Stop Coidng",
    "text": "3.4 Stop Coidng\nA key part to improving our code often involves taking a step back. Rather than charging ahead we can figure out what we want to accomplish and the steps we need to get there."
  },
  {
    "objectID": "02_add_automated_test.html#make-a-plan",
    "href": "02_add_automated_test.html#make-a-plan",
    "title": "3  Add an Automated Test",
    "section": "3.5 Make a Plan",
    "text": "3.5 Make a Plan\nA common practice in software development is to write down a sketch of the data we have and a sketch of the data we want. Then, we chart out the individual steps to get us from where we are to where we want to be.\nThis approach can help us build stronger intuitions about how to engineer and validate data. Using this strategy also prevents us from getting lost in a maze of code we don’t understand why we wrote.\nThere are plenty of ways to make this plan happen. You can write it in a physical notebook, a Google Doc, etc. I tend to like writing pseudocode with comments like my solutions already magically exist. For example:\n\n# I have data with duplicate IDs in it right now\n\nnon_duplicated_data <- duplicated_data %>% \n  # I want to remove those duplicate IDs only leaving the most recent row but retain all information\n  disapper_duplicates(most_recent = TRUE, keep_everything = TRUE) %>% \n  # And then have data with no duplicates, all other info, and only the most recent of each ID\n  print()\n\nError in disapper_duplicates(., most_recent = TRUE, keep_everything = TRUE): could not find function \"disapper_duplicates\"\n\n\ndisappear_duplicates() isn’t a real function, and now that I’ve thought about what I’m looking to accomplish finding a real function will be easier.\n\n3.5.1 Our Goal in Data Engineering is Tidy, Accurate Data\nWhen we’re making a plan while data engineering, we know we want to end up with tidy, accurate data. Our engineering and validation efforts are steps toward this ultimate goal.\n\n\n3.5.2 The Definition of Tidy Depends on Context\n\nTidy data is data where:\n\nEvery column is a variable\nEvery row is an observation\nEvery cell is a single value\n\n\nHowever, what counts as a “single value” or “observation” can vary based on context. For example, if we want data with every measurement of our penguins our defintion of “a single value” will be different than if we want data with only the most recent measurement from each penguin.\nCode and automated pipelines can’t make these decisions for us. These are people problems masquerading as coding problems.\n\n\n3.5.3 The Definiton of Accurate Depends on Context\nThis is even more true when it comes to an organization’s definition of “accurate.” Almost no real-world dataset will ever achieve 100% accuracy in its data, so we have to prioritize. How much do we care if there are duplicate IDs in the data? Impossible values in our key outcomes?\nBehaviors betray priorities here. We implicitly say we don’t care much about potential errors if we don’t bother to check. Or at least we don’t care as much about those errors as other organizational priorities. That decision might be right or wrong, but either way it’s a human process that no amount of code can solve directly."
  },
  {
    "objectID": "02_add_automated_test.html#convert-plans-into-real-code",
    "href": "02_add_automated_test.html#convert-plans-into-real-code",
    "title": "3  Add an Automated Test",
    "section": "3.6 Convert Plans Into Real Code",
    "text": "3.6 Convert Plans Into Real Code\nLet’s say our definition of tidy data in this case is only one measurement per penguin. We also know1 that we only want the last measurement collected from each penguin. We already wrote pseudocode with comments up above to handle this situation. We can express those plans with actual code here:\n\npenguins_unique_sample <- penguins_improved_redux %>% # Data with duplicates\n  arrange(desc(date_egg)) %>% # Order the dataset with most recent measurements first\n  distinct(individual_id, .keep_all = TRUE) # Keep only distinct individual_id rows and keep all the other columns"
  },
  {
    "objectID": "02_add_automated_test.html#lets-finish-this-upgraded-pipeline",
    "href": "02_add_automated_test.html#lets-finish-this-upgraded-pipeline",
    "title": "3  Add an Automated Test",
    "section": "3.11 Let’s Finish This Upgraded Pipeline",
    "text": "3.11 Let’s Finish This Upgraded Pipeline\nWe then read this processed data without duplicate IDs into a “processed/” folder to finish out our pipeline.\n\noutput_path_processed <- here::here(\"data_from_gsheets/processed/palmer_penguins_improved.csv\")\n\nwrite_csv(penguins_unique_sample, output_path_processed)\n\nIf all our end-users need is penguins data without duplicate IDs we’re set! And most organizations have far more than one dataset of interest. Let’s extend our pipeline to automatically handle multiple datasets."
  },
  {
    "objectID": "02_add_automated_test.html#finish-this-upgraded-pipeline",
    "href": "02_add_automated_test.html#finish-this-upgraded-pipeline",
    "title": "3  Add an Automated Test",
    "section": "3.11 Finish This Upgraded Pipeline",
    "text": "3.11 Finish This Upgraded Pipeline\nWe then write this processed data without duplicate IDs into a “processed/” folder to finish out our pipeline.\n\noutput_path_processed <- here::here(\"data_from_gsheets/processed/palmer_penguins_improved.csv\")\n\nwrite_csv(penguins_unique_sample, output_path_processed)\n\nAnd let’s also write a version of the automated test report into another folder.\n\nreport_path_processed <- here::here(glue(\"reports/processed/{now()}_palmer_penguins_report.html\"))\n\n# Commented out here so we don't create a new version of the report during every reload\n# export_report(penguins_distinct_agent, report_path_processed)\n\nIf all our end-users need is penguins data without duplicate IDs we’re set! And we even have a report that will automatically save when we run the script so we’ll know if we passed the data quality checks.\nAnd most organizations have far more than one dataset of interest. Let’s extend our pipeline to automatically handle multiple datasets."
  },
  {
    "objectID": "02_add_automated_test.html#stop-coding",
    "href": "02_add_automated_test.html#stop-coding",
    "title": "3  Add an Automated Test",
    "section": "3.4 Stop Coding",
    "text": "3.4 Stop Coding\nA key part to improving our code often involves taking a step back. Rather than charging ahead we can figure out what we want to accomplish and the steps we need to get there."
  },
  {
    "objectID": "03_handle_multiple_datasets.html",
    "href": "03_handle_multiple_datasets.html",
    "title": "4  Handle Multiple Datasets",
    "section": "",
    "text": "library(googlesheets4)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\nlibrary(pointblank)\nlibrary(glue)"
  },
  {
    "objectID": "03_handle_multiple_datasets.html#what-if-we-want-our-pipeline-to-include-more-than-one-dataset",
    "href": "03_handle_multiple_datasets.html#what-if-we-want-our-pipeline-to-include-more-than-one-dataset",
    "title": "4  Handle Multiple Datasets",
    "section": "4.2 What If We Want Our Pipeline to Include More Than One Dataset?",
    "text": "4.2 What If We Want Our Pipeline to Include More Than One Dataset?\nNearly every organization will have multiple datasets in need of engineering. A temptation when updating our pipeline is to just copy/paste the code we used for a previous dataset.\nWhile this might be faster at first, this approach scales terribly. And even if you have the finest attention to detail you’re bound to make a mistake at some point.\nSo what do we do instead?\nWe use functions that allow us to do the same process many times automatically. These functions will allow us to write a similar amount of code for handling 100 datasets as we did for handling 1 dataset.\nThe first function we’ll use to read in three datasets at once is called map()."
  },
  {
    "objectID": "03_handle_multiple_datasets.html#a-walkthrough-modifying-our-previous-code",
    "href": "03_handle_multiple_datasets.html#a-walkthrough-modifying-our-previous-code",
    "title": "4  Handle Multiple Datasets",
    "section": "4.3 A Walkthrough Modifying Our Previous Code",
    "text": "4.3 A Walkthrough Modifying Our Previous Code\n\n# Since this Google Sheet is public to anyone with the link we don't need\n# to authenticate\n\ngs4_deauth()\n\n# Get the IDs of our Google Sheets\n\nsheet_ids <- c(\"1v0lG-4arxF_zCCpfoUzCydwzaea7QqWTTQzTr8Dompw\",\n               \"1wPmFajaVyWIImmvEyf6wp16mAkX1PGC5jyKUx7s7DBQ\",\n               \"1Biy_OhNxkaWDteBQt7AfzD89g1j2NY7mctYr50S2WVg\")\n\n# Read in all the data using the googlesheets4 package\n\nall_datasets_raw <- map(sheet_ids, ~read_sheet(.x, na = \"NA\"))\n\nThere are more complicated, technically correct ways to think about what map() does, but for now:\nmap() lets us write code like we’re doing the process once1, replace the single instance2 with a placeholder .x, and run the code on a bunch of instances3.\nThis is a lot to get our brains around at first, and it’s one of the engines that makes scalable, reproducible data pipelines possible. For a resource focused on helping you understand map() click here"
  },
  {
    "objectID": "03_handle_multiple_datasets.html#write-raw-data-all-at-once",
    "href": "03_handle_multiple_datasets.html#write-raw-data-all-at-once",
    "title": "4  Handle Multiple Datasets",
    "section": "4.4 Write Raw Data All at Once",
    "text": "4.4 Write Raw Data All at Once\nWhat if we want to use map() with two inputs instead of one? map2() has us covered!\n\n# Creating all output paths (Could still be further optimized!)\n\noutput_paths_improved <- c(here::here(\"data_from_gsheets/raw/palmer_penguins_improved.csv\"),\n                           here::here(\"data_from_gsheets/raw/wellbeing.csv\"),\n                           here::here(\"data_from_gsheets/raw/telemetry.csv\"))\n\n# Writing all the files as .csv (Note: Could use `walk` instead of `map` because this is side effect only output)\n\nmap2(all_datasets_raw, output_paths_improved, ~write_csv(.x, .y))\n\nAnd we can actually future-proof this process even more.\nA mental exercise I use: Would this code be awful to type if there were 100 cases?\nI definitely don’t want to type out 100 full paths if I don’t have to.\nWe’ll also introduce a for loop, which works like map() and is a more common way to do the same process lots of times across coding languages.\nYou can also see why I favor map() when writing in R since it can compress ~20 lines of code into as few as 1.\n\n# Write way less per path\n\nfile_names <- c(\"palmer_penguins_improved\",\n                \"wellbeing\",\n                \"telemetry\")\n\n# Start with an empty list of file paths\n\noutput_paths_loop <- list()\n\n# Create the for loop that will create a populated list of file paths\n\nfor (file_name in file_names) {\n  \n  # Create the string needed for the file path using `glue`\n  \n  path_init <- glue(\"data_from_gsheets/raw/{file_name}.csv\")\n  \n  # Create the path itself using `here`\n  # Note, we could do this all at once but it's less readable\n  \n  path <- here::here(path_init)\n  \n  # Append (or add to the end) the current path to the formerly empty list\n  \n  output_paths_loop <- append(output_paths_loop, path)\n  \n}\n\nIf we were following this process we’d then make sure to write our datasets into the raw folder.\n\n# Writing all the files as .csv (Note: Could use `walk` instead of `map` because this is side effect only output)\n\nmap2(all_datasets_raw, output_paths_loop, ~write_csv(.x, .y))"
  },
  {
    "objectID": "03_handle_multiple_datasets.html#add-some-pre-processing-to-our-multi-dataset-pipeline",
    "href": "03_handle_multiple_datasets.html#add-some-pre-processing-to-our-multi-dataset-pipeline",
    "title": "4  Handle Multiple Datasets",
    "section": "4.5 Add Some Pre-Processing to Our Multi-Dataset Pipeline",
    "text": "4.5 Add Some Pre-Processing to Our Multi-Dataset Pipeline\nLet’s start by using the {janitor} package to clean up our column names across all the datasets, rather than just one. We’ll switch back to map() for this version of “do multiple datasets at once.”\n\nall_datasets_initial <- map(file_names, ~{\n  \n  # Create file name\n  \n  path_for_read <- glue(\"data_from_gsheets/raw/{.x}.csv\")\n  \n  # Read in the csv and clean the column names\n  \n  read_csv(path_for_read) %>%\n    clean_names()\n  \n})"
  },
  {
    "objectID": "03_handle_multiple_datasets.html#lets-scan-our-data-for-any-obvious-problems",
    "href": "03_handle_multiple_datasets.html#lets-scan-our-data-for-any-obvious-problems",
    "title": "4  Handle Multiple Datasets",
    "section": "4.6 Let’s Scan Our Data for Any Obvious Problems",
    "text": "4.6 Let’s Scan Our Data for Any Obvious Problems\nWe can still scan a single dataset by calling its position in our list.\nscan_data(all_datasets_initial[[2]], sections = \"O\")\n\n\n\n\n\n        \n    \n    \n  \n\n\n\n\n\n\nOverview of all_datasets_initial[[2]]\n\n\n\n\n\nOverview\n\n\nReproducibility\n\n\n\n\n\nTable Overview\n\n\n\n  \n  \n    Columns\n\n11\n    Rows\n\n238\n    NAs\n\n0\n    Duplicate Rows\n\n0\n  \n  \n  \n\n\n\n\nColumn Types\n\n\n\n  \n  \n    numeric\n11\n  \n  \n  \n\n\n\n\n\n\nReproducibility Information\n\n\n\n  \n  \n    Scan Build Time\n\n2023-09-26 16:27:26\n\n    pointblank Version\n\n0.11.4\n\n    R Version\n\nR version 4.1.3 (2022–03–10)One Push–Up\n\n    Operating System\n\nx86_64-apple-darwin17.0\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\nTable scan generated with pointblank.\n\n\n\n\n\n\n\n\nBut we can also scan all our datasets at once and then output the reports.\nmany_reports <- map(all_datasets_initial, ~scan_data(.x, sections = \"O\"))\nmany_reports[[2]]\n\n\n\n\n\n        \n    \n    \n  \n\n\n\n\n\n\nOverview of .x\n\n\n\n\n\nOverview\n\n\nReproducibility\n\n\n\n\n\nTable Overview\n\n\n\n  \n  \n    Columns\n\n11\n    Rows\n\n238\n    NAs\n\n0\n    Duplicate Rows\n\n0\n  \n  \n  \n\n\n\n\nColumn Types\n\n\n\n  \n  \n    numeric\n11\n  \n  \n  \n\n\n\n\n\n\nReproducibility Information\n\n\n\n  \n  \n    Scan Build Time\n\n2023-09-26 16:27:26\n\n    pointblank Version\n\n0.11.4\n\n    R Version\n\nR version 4.1.3 (2022–03–10)One Push–Up\n\n    Operating System\n\nx86_64-apple-darwin17.0\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\nTable scan generated with pointblank."
  },
  {
    "objectID": "03_handle_multiple_datasets.html#we-now-have-a-reproducible-scalable-pipeline-with-automatic-checks-for-duplicate-ids",
    "href": "03_handle_multiple_datasets.html#we-now-have-a-reproducible-scalable-pipeline-with-automatic-checks-for-duplicate-ids",
    "title": "4  Handle Multiple Datasets",
    "section": "4.8 We Now Have a Reproducible, Scalable Pipeline with Automatic Checks for Duplicate IDs",
    "text": "4.8 We Now Have a Reproducible, Scalable Pipeline with Automatic Checks for Duplicate IDs\nIt’s worthwhile to pause here to think how much better than the status quo this is at many organizations. You can run this script anytime you want, get updated data across as many datasets as you have, and check all those datasets for duplicate IDs. This is a great accomplishment by itself, and we’re not done yet.\nWe’re going to tackle how these map functions work in detail and use them to apply specific checks to some datasets but not others."
  },
  {
    "objectID": "03_handle_multiple_datasets.html#we-can-still-automatically-check-our-data-across-many-datasets",
    "href": "03_handle_multiple_datasets.html#we-can-still-automatically-check-our-data-across-many-datasets",
    "title": "4  Handle Multiple Datasets",
    "section": "4.7 We Can Still Automatically Check Our Data Across Many Datasets",
    "text": "4.7 We Can Still Automatically Check Our Data Across Many Datasets\nThere are certain data quality checks we’re going to want to do across all of our datasets. A lack of duplicate IDs is an example of one such check, so let’s start there. Don’t worry if you don’t understand all this code yet, we’re going to dive deep in the next chapter into how it works step by step.\n\n# Need to input the datasets and the name of the id variable for each\n\nid_var_names <- c(\"individual_id\",\"participant_id\", \"id\")\n\nall_agents <- map2(all_datasets_initial, id_var_names, ~{\n  \n  .x %>%\n    create_agent(\n      label = \"Check for unique ids\",\n      actions = action_levels(warn_at = 1)\n    ) %>%\n    rows_distinct(\n      columns = vars(!!!.y)\n    ) %>%\n    interrogate()\n  \n})\n\nall_agents[[3]]\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n      Pointblank Validation\n    \n    \n      Check for unique ids\ntibbleWARN\n1\nSTOP\n—\nNOTIFY\n—\n\n    \n    \n      \n      \n      STEP\n      COLUMNS\n      VALUES\n      TBL\n      EVAL\n      UNITS\n      PASS\n      FAIL\n      W\n      S\n      N\n      EXT\n    \n  \n  \n    \n1\n\n      rows_distinct                                                                                                            \n   rows_distinct()\n\n\n\n  \n    ▮id\n  \n\n\n—\n                                                            \n\n✓\n\n1K\n1K1.00\n00.00\n○\n\n—\n\n—\n\n—\n\n  \n  \n    \n      2023-09-26 15:15:36 MDT\n< 1 s\n2023-09-26 15:15:36 MDT"
  },
  {
    "objectID": "04_different_checks_different_datasets.html",
    "href": "04_different_checks_different_datasets.html",
    "title": "5  Different Checks for Different Datasets",
    "section": "",
    "text": "library(googlesheets4)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\nlibrary(pointblank)\nlibrary(glue)\nlibrary(gt)\nlibrary(knitr)\nlibrary(lubridate)"
  },
  {
    "objectID": "04_different_checks_different_datasets.html#lets-be-real-different-datasets-will-require-different-checks",
    "href": "04_different_checks_different_datasets.html#lets-be-real-different-datasets-will-require-different-checks",
    "title": "5  Different Checks for Different Datasets",
    "section": "5.2 Let’s Be Real, Different Datasets Will Require Different Checks",
    "text": "5.2 Let’s Be Real, Different Datasets Will Require Different Checks\nWhile there are certain checks we’ll want to do in a vast majority of datasets,1 we’ll need different automated checks for different datasets.\nThis might feel like a huge wrench in our plan for automated checks, but it’s not! Let’s walk through how we can keep our pipeline moving."
  },
  {
    "objectID": "04_different_checks_different_datasets.html#lets-read-in-all-our-raw-data",
    "href": "04_different_checks_different_datasets.html#lets-read-in-all-our-raw-data",
    "title": "5  Different Checks for Different Datasets",
    "section": "5.3 Let’s Read in All Our Raw Data",
    "text": "5.3 Let’s Read in All Our Raw Data\n\n# Write way less per path\n\nfile_names <- c(\"palmer_penguins_improved\",\n                \"wellbeing\",\n                \"telemetry\")\n\nall_datasets_different <- map(file_names, ~{\n  \n  # Create file name\n  \n  path_for_read <- glue(\"data_from_gsheets/raw/{.x}.csv\")\n  \n  # Read in the csv and clean the column names\n  \n  read_csv(path_for_read) %>%\n    clean_names()\n  \n})"
  },
  {
    "objectID": "04_different_checks_different_datasets.html#creating-flags-for-different-kinds-of-checks",
    "href": "04_different_checks_different_datasets.html#creating-flags-for-different-kinds-of-checks",
    "title": "5  Different Checks for Different Datasets",
    "section": "5.4 Creating ‘Flags’ For Different Kinds of Checks",
    "text": "5.4 Creating ‘Flags’ For Different Kinds of Checks\nLet’s start with the example we’ve seen before, checking for duplicate IDs. Let’s say we’re not concerned about duplicate IDs in the telemetry data, but we still want to do that check in the palmer_penguins and well_being datasets.\nWe can create a “flag” for the duplicate ID check. “Flag” is just a somewhat fancy way of saying a variable that returns TRUE when we want to perform the check and FALSE when we don’t.\nHere’s what that looks like in code. Don’t worry if there’s a lot here you don’t understand yet, we’ll go through a version step by step later!\n\n# Need to input the datasets and the name of the id variable for each\n\nid_var_names <- c(\"individual_id\",\"participant_id\", \"id\")\n\ncheck_dupe_ids <- c(rep(TRUE, 2),rep(FALSE, 1))\n\nall_agents_conditional <- pmap(list(all_datasets_different, \n                                    id_var_names, \n                                    check_dupe_ids), ~{\n  \n  if(..3 == TRUE) {\n    \n    ..1 %>%\n    create_agent(\n      label = \"Check for unique ids\",\n      actions = action_levels(warn_at = 1)\n    ) %>%\n    rows_distinct(\n      columns = vars(!!!..2)\n    ) %>%\n    interrogate()\n    \n  } else {\n    \n    data.frame(no_check = TRUE) %>% \n    gt() %>% \n      tab_header(\"No Check for Duplicate IDs\")\n    \n  }\n  \n  \n})\n\nall_agents_conditional[[3]]\n\n\n\n\n\n  \n    \n      No Check for Duplicate IDs\n    \n    \n    \n      no_check\n    \n  \n  \n    TRUE\n  \n  \n  \n\n\n\n\nWe have to introduce a new extension of the map() function: pmap().\nRemember how we had map2() when we had two variables we wanted to iterate over at the same time? Rather than have map3() for 3 inputs, map4() for 4 inputs, etc. we can use pmap with however many inputs we want.\nThe biggest differences when using pmap is that instead of.x and .y we could use ..1 for the first input, ..2 for the second input, etc.\nWe then use an if else statement to only perform the check for duplicate IDs when our flag equals TRUE. If it’s false we create a table output explicitly saying the check wasn’t performed."
  },
  {
    "objectID": "04_different_checks_different_datasets.html#creating-more-scalable-automated-checks",
    "href": "04_different_checks_different_datasets.html#creating-more-scalable-automated-checks",
    "title": "5  Different Checks for Different Datasets",
    "section": "5.5 Creating More Scalable, Automated Checks",
    "text": "5.5 Creating More Scalable, Automated Checks\nThis is a great start, and I could imagine this getting unwieldy with even one more kind of check. If we wanted to add a variety of checks that do and don’t apply to different datasets this code would become an impossible mess.\nLet’s add another check and create a more scalable version of this code.\nFirst let’s create the values we’ll need for our checks. We’ll need to grab the names of the columns we’re checking.\n\n# Create necessary input for id variable names\n\nid_var_names <- c(\"individual_id\",\"participant_id\", \"id\")\n\n# Get the names of variables whose values we want to check\n\nvars_value_check <- list(all_datasets_different[[1]] %>% \n                          select(starts_with(\"culmen\")) %>% \n                          names(),\n                      all_datasets_different[[2]] %>% \n                        select(starts_with(\"wellbeing\")) %>% \n                        names(),\n                      all_datasets_different[[3]] %>% \n                        select(starts_with(\"accelerometer\")) %>% \n                        names())\n\nBut we know how to spot non-scalable copy-paste + coding now! Let’s create a couple functions and map over them to get those column names more efficiently.\n\nid_var_names <- map(all_datasets_different, ~{\n  \n  .x %>% \n    select(ends_with(\"id\")) %>% \n    names()\n  \n})\n\nvar_start_with <- list(\"culmen\",\"wellbeing\",\"accelerometer\")\n\nvars_value_check <- map2(all_datasets_different, var_start_with, ~{\n  \n  .x %>% \n    select(starts_with(.y)) %>% \n    names()\n  \n})\n\nNotice how the ends_with(\"id\") call is only possible because all our ID variables end with the characters “id”\nNaming things well and consistently is just as much a part of data engineering as writing code part 87!\nAnyway, let’s create the flags for our checks. We’ll use the rep() function to reduce keystrokes and make our flags more scalable.\n\n# Create check flags\n\ncheck_dupe_ids <- c(rep(TRUE, 2),rep(FALSE, 1))\n\ncheck_var_range <- c(rep(FALSE, 1), rep(TRUE, 2))\n\nAnd now we get to pmap(). First we’ll create a function that uses the ..1, ..2, ..3 etc. to make our function work.\n\n# Create more scalable pmap\n\nall_agents_conditional <- pmap(.l = list(all_datasets_different, \n                                         id_var_names, \n                                         check_dupe_ids,\n                                         check_var_range,\n                                         vars_value_check),\n                               ~{\n    \n    ..1 %>%\n      create_agent(\n        label = \"Conduct automated checks\",\n        actions = action_levels(warn_at = 1)\n      ) %>%\n      {if (..3 == TRUE)\n        rows_distinct(.,\n          columns = vars(!!!..2)\n          )\n        else .\n        } %>%\n      {if (..4 == TRUE)\n        pointblank::col_vals_between(.,\n          columns = ..5,\n          left = -4,\n          right = 4,\n          na_pass = TRUE\n        )\n        else .\n        } %>% \n      interrogate()\n\n  \n})\n\nThis code will technically run, give us the right output, and use functions to make it more scalable.\nIt’s also really hard to figure out which variable is which and what is happening! Let’s create a version where we name all the variables we’re passing into pmap() instead.\n\nall_agents_conditional <- pmap(.l = list(dataset_for_check = all_datasets_different, \n                                         id = id_var_names, \n                                         check_dupe_ids = check_dupe_ids,\n                                         check_var_range = check_var_range,\n                                         vars_value_check = vars_value_check),\n                               .f = function(dataset_for_check,\n                                             id,\n                                             check_dupe_ids,\n                                             check_var_range,\n                                             vars_value_check) {\n    \n    dataset_for_check %>%\n      create_agent(\n        label = \"Conduct automated tests\",\n        actions = action_levels(warn_at = 1)\n      ) %>%\n      {if (check_dupe_ids == TRUE)\n        rows_distinct(.,\n          columns = vars(!!!id)\n          )\n        else .\n        } %>%\n      {if (check_var_range == TRUE)\n        pointblank::col_vals_between(.,\n          columns = vars_value_check,\n          left = -4,\n          right = 4,\n          na_pass = TRUE\n        )\n        else .\n        } %>% \n      interrogate()\n\n  \n})"
  },
  {
    "objectID": "04_different_checks_different_datasets.html#preprocessing-based-on-tests",
    "href": "04_different_checks_different_datasets.html#preprocessing-based-on-tests",
    "title": "5  Different Checks for Different Datasets",
    "section": "5.8 Preprocessing Based on Tests",
    "text": "5.8 Preprocessing Based on Tests\nLet’s apply the necessary preprocessing to the datasets, also using pmap() with preprocessing flags.\nThis applies the same logic as our initial checks but this time we’ll do a preprocessing step or not based on the flag.\nFor example, we won’t run distinct() on the telemetry dataset because we aren’t concerned about duplicate IDs in that data.\n\nall_datasets_processed <- pmap(.l = list(dataset_for_clean = all_datasets_different, id = id_var_names, \n                                    clean_dupe_ids = check_dupe_ids, clean_var_range = check_var_range,\n                                    vars_value_check = vars_value_check),\n                               .f = function(dataset_for_clean,\n                                             id,\n                                             clean_dupe_ids,\n                                             clean_var_range,\n                                             vars_value_check) {\n    \n    dataset_for_clean %>%\n      {if (clean_dupe_ids == TRUE)\n        distinct(.,\n          pick(contains(id)), .keep_all = TRUE)\n        else .\n        } %>%\n      {if (clean_var_range == TRUE)\n        mutate(.,\n               across(\n                 .cols = c(!!!vars_value_check),\n                 .fns = ~case_when(\n                   .x > 4 ~ 4.0,\n                   .x < -4 ~ -4.0,\n                   TRUE ~ .x\n                 )\n               )\n        )\n        else .\n        }\n\n  \n})\n\nAnd finally let’s re-run our tests\n\nall_agents_processed <- pmap(.l = list(dataset_for_check = all_datasets_processed, id = id_var_names, \n                                    check_dupe_ids = check_dupe_ids, check_var_range = check_var_range,\n                                    vars_value_check = vars_value_check),\n                               .f = function(dataset_for_check,\n                                             id,\n                                             check_dupe_ids,\n                                             check_var_range,\n                                             vars_value_check) {\n    \n    dataset_for_check %>%\n      create_agent(\n        label = \"Conduct automated tests\",\n        actions = action_levels(warn_at = 1)\n      ) %>%\n      {if (check_dupe_ids == TRUE)\n        rows_distinct(.,\n          columns = vars(!!!id)\n          )\n        else .\n        } %>%\n      {if (check_var_range == TRUE)\n        pointblank::col_vals_between(.,\n          columns = vars_value_check,\n          left = -4,\n          right = 4,\n          na_pass = TRUE\n        )\n        else .\n        } %>% \n      interrogate()\n\n  \n})\n\nall_agents_processed[[1]]\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n      Pointblank Validation\n    \n    \n      Conduct automated tests\ntibbleWARN\n1\nSTOP\n—\nNOTIFY\n—\n\n    \n    \n      \n      \n      STEP\n      COLUMNS\n      VALUES\n      TBL\n      EVAL\n      UNITS\n      PASS\n      FAIL\n      W\n      S\n      N\n      EXT\n    \n  \n  \n    \n1\n\n      rows_distinct                                                                                                            \n   rows_distinct()\n\n\n\n  \n    ▮individual_id\n  \n\n\n—\n                                                            \n\n✓\n\n190\n1901.00\n00.00\n○\n\n—\n\n—\n\n—\n\n  \n  \n    \n      2023-09-26 16:54:33 MDT\n< 1 s\n2023-09-26 16:54:33 MDT\n    \n  \n  \n\n\n\nall_agents_processed[[2]]\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n      Pointblank Validation\n    \n    \n      Conduct automated tests\ntibbleWARN\n1\nSTOP\n—\nNOTIFY\n—\n\n    \n    \n      \n      \n      STEP\n      COLUMNS\n      VALUES\n      TBL\n      EVAL\n      UNITS\n      PASS\n      FAIL\n      W\n      S\n      N\n      EXT\n    \n  \n  \n    \n1\n\n      rows_distinct                                                                                                            \n   rows_distinct()\n\n\n\n  \n    ▮participant_id\n  \n\n\n—\n                                                            \n\n✓\n\n236\n2361.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n2\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_1\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n236\n2361.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n3\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_2\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n236\n2361.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n4\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_3\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n236\n2361.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n5\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_4\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n236\n2361.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n6\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_5\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n236\n2361.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n7\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_6\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n236\n2361.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n8\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_7\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n236\n2361.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n9\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_8\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n236\n2361.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n10\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_9\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n236\n2361.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n11\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_10\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n236\n2361.00\n00.00\n○\n\n—\n\n—\n\n—\n\n  \n  \n    \n      2023-09-26 16:54:33 MDT\n< 1 s\n2023-09-26 16:54:33 MDT\n    \n  \n  \n\n\n\nall_agents_processed[[3]]\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n      Pointblank Validation\n    \n    \n      Conduct automated tests\ntibbleWARN\n1\nSTOP\n—\nNOTIFY\n—\n\n    \n    \n      \n      \n      STEP\n      COLUMNS\n      VALUES\n      TBL\n      EVAL\n      UNITS\n      PASS\n      FAIL\n      W\n      S\n      N\n      EXT\n    \n  \n  \n    \n1\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮accelerometer_axis_1\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n1K\n1K1.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n2\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮accelerometer_axis_2\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n1K\n1K1.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n3\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮accelerometer_axis_3\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n1K\n1K1.00\n00.00\n○\n\n—\n\n—\n\n—\n\n  \n  \n    \n      2023-09-26 16:54:33 MDT\n< 1 s\n2023-09-26 16:54:33 MDT"
  },
  {
    "objectID": "04_different_checks_different_datasets.html#finishing-the-pipeline-by-writing-the-new-datasets-to-processed-data",
    "href": "04_different_checks_different_datasets.html#finishing-the-pipeline-by-writing-the-new-datasets-to-processed-data",
    "title": "5  Different Checks for Different Datasets",
    "section": "5.9 Finishing the Pipeline by Writing the New Datasets to Processed Data…",
    "text": "5.9 Finishing the Pipeline by Writing the New Datasets to Processed Data…\n\n# Write way less per path\n\nfile_names <- c(\"palmer_penguins_improved\",\n                \"wellbeing\",\n                \"telemetry\")\n\n# Start with an empty list of file paths\n\noutput_paths_processed <- list()\n\n# Create the for loop that will create a populated list of file paths\n\nfor (file_name in file_names) {\n  \n  # Create the string needed for the file path using `glue`\n  \n  path_init <- glue(\"data_from_gsheets/processed/{file_name}.csv\")\n  \n  # Create the path itself using `here`\n  # Note, we could do this all at once but it's less readable\n  \n  path <- here::here(path_init)\n  \n  # Append (or add to the end) the current path to the formerly empty list\n  \n  output_paths_processed <- append(output_paths_processed, path)\n  \n}\n\n\nmap2(all_datasets_processed, output_paths_processed, ~write_csv(.x, .y))"
  },
  {
    "objectID": "04_different_checks_different_datasets.html#a-deep-dive-into-pmap",
    "href": "04_different_checks_different_datasets.html#a-deep-dive-into-pmap",
    "title": "5  Different Checks for Different Datasets",
    "section": "5.6 A Deep Dive Into pmap()",
    "text": "5.6 A Deep Dive Into pmap()\nStill probably intimidating if you’ve never seen a pmap() function before.2 Let’s break down each part of this function using plain language.\nThis part of the function lets us name our inputs. We can either give them shorter names (e.g., “id” instead of “id_var_names”) or keep them the same (“check_var_range”).\n\n# .l = list(dataset_for_check = all_datasets_different,\n#           id = id_var_names,\n#           check_dupe_ids = check_dupe_ids, \n#           check_var_range = check_var_range,\n#           vars_value_check = vars_value_check)\n\nThis part of the function let’s pmap know we’re going to execute a function using the parameters we just created instead of ..l etc. Naming these parameters here lets us use those names in the function itself, which is way easier to understand than ..1 or ..2.\n\n# .f = function(dataset_for_check,\n#               id,\n#               check_dupe_ids,\n#               check_var_range,\n#               vars_value_check\n#               )\n\nIn this chunk of the code we take a dataset from our list of raw datasets and create an agent using the {pointblank} package. We also tell the process to warn us if there’s even one failure.3\n\n# dataset_for_check %>%\n#       create_agent(\n#         label = \"Conduct automated tests\",\n#         actions = action_levels(warn_at = 1)\n#       ) \n\nThis looks a bit different than anything we’ve seen so far. What this code allows us to do is say “Hey, if we said we wanted to check if there were duplicate IDs4 then check if there are duplicate IDs5. Otherwise, just pass the dataframe through the pipleline as is without checking for duplicate IDs[else .].”\nAnother note, the !!!id looks a bit wild, and you don’t have to fully understand what’s happening there right now. All you need to know is this is one way to “unquote” variables that are passed in as character values6 but for coding purposes need to not have quotes around them.7 For more in depth discussion of this topic you can check out this resource.\n\n# {if (check_dupe_ids == TRUE)\n#         rows_distinct(.,\n#           columns = vars(!!!id)\n#           )\n#         else .\n#         }\n\nThis chunk follows the same logic as the previous chunk, just for a different kind of check. “Hey, if we said we wanted to check if some columns only had values inside of a certain range8 then check the columns we specify for only values between a certain range9. Otherwise, just pass the dataframe through the pipleline as is without checking for if some columns only had values inside of a certain range[else .].”\n\n# {if (check_var_range == TRUE)\n#         pointblank::col_vals_between(.,\n#           columns = vars_value_check,\n#           left = -4,\n#           right = 4,\n#           na_pass = TRUE\n#         )\n#         else .\n#         }\n\nAnd this final bit produces the reports for each dataset!\n\n#interrogate()"
  },
  {
    "objectID": "04_different_checks_different_datasets.html#looking-at-our-reports",
    "href": "04_different_checks_different_datasets.html#looking-at-our-reports",
    "title": "5  Different Checks for Different Datasets",
    "section": "5.7 Looking at Our Reports",
    "text": "5.7 Looking at Our Reports\nLets look at those reports now.\n# Breaking my own rule about not copy/pasting code here since if I try \n# to print list of agents all at once the formatting looks terrible \n# in the book\n\nall_agents_conditional[[1]]\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n      Pointblank Validation\n    \n    \n      Conduct automated tests\ntibbleWARN\n1\nSTOP\n—\nNOTIFY\n—\n\n    \n    \n      \n      \n      STEP\n      COLUMNS\n      VALUES\n      TBL\n      EVAL\n      UNITS\n      PASS\n      FAIL\n      W\n      S\n      N\n      EXT\n    \n  \n  \n    \n1\n\n      rows_distinct                                                                                                            \n   rows_distinct()\n\n\n\n  \n    ▮individual_id\n  \n\n\n—\n                                                            \n\n✓\n\n344\n760.22\n2680.78\n●\n\n—\n\n—\n\n\n  CSV\n\n\n  \n  \n    \n      2023-09-26 16:54:29 MDT\n< 1 s\n2023-09-26 16:54:29 MDT\n    \n  \n  \n\n\n\nall_agents_conditional[[2]]\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n      Pointblank Validation\n    \n    \n      Conduct automated tests\ntibbleWARN\n1\nSTOP\n—\nNOTIFY\n—\n\n    \n    \n      \n      \n      STEP\n      COLUMNS\n      VALUES\n      TBL\n      EVAL\n      UNITS\n      PASS\n      FAIL\n      W\n      S\n      N\n      EXT\n    \n  \n  \n    \n1\n\n      rows_distinct                                                                                                            \n   rows_distinct()\n\n\n\n  \n    ▮participant_id\n  \n\n\n—\n                                                            \n\n✓\n\n238\n2340.98\n40.02\n●\n\n—\n\n—\n\n\n  CSV\n\n\n    \n2\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_1\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n238\n2381.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n3\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_2\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n238\n2381.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n4\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_3\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n238\n2381.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n5\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_4\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n238\n2381.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n6\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_5\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n238\n2381.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n7\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_6\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n238\n2381.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n8\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_7\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n238\n2381.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n9\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_8\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n238\n2381.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n10\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_9\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n238\n2381.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n11\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮wellbeing_item_10\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n238\n2381.00\n00.00\n○\n\n—\n\n—\n\n—\n\n  \n  \n    \n      2023-09-26 16:54:29 MDT\n< 1 s\n2023-09-26 16:54:30 MDT\n    \n  \n  \n\n\n\nall_agents_conditional[[3]]\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n      Pointblank Validation\n    \n    \n      Conduct automated tests\ntibbleWARN\n1\nSTOP\n—\nNOTIFY\n—\n\n    \n    \n      \n      \n      STEP\n      COLUMNS\n      VALUES\n      TBL\n      EVAL\n      UNITS\n      PASS\n      FAIL\n      W\n      S\n      N\n      EXT\n    \n  \n  \n    \n1\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮accelerometer_axis_1\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n1K\n1K1.00\n00.00\n○\n\n—\n\n—\n\n—\n\n    \n2\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮accelerometer_axis_2\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n1K\n1K0.99\n10.01\n●\n\n—\n\n—\n\n\n  CSV\n\n\n    \n3\n\n      col_vals_between                                                \n   col_vals_between()\n\n\n\n  \n    ▮accelerometer_axis_3\n  \n\n\n[−4, 4]\n\n                                                            \n\n✓\n\n1K\n1K0.99\n20.01\n●\n\n—\n\n—\n\n\n  CSV\n\n\n  \n  \n    \n      2023-09-26 16:54:30 MDT\n< 1 s\n2023-09-26 16:54:30 MDT\n    \n  \n  \n\n\n\nWe now have automated, different checks across multiple datasets!\nWe didn’t check whether values fell within a certain range in the palmer_penguins data, we didn’t check for duplicate IDs in our telemetry data, and we performed both of those checks in the wellbeing data.\nWe also caught duplicate IDs in both datasets where we checked, along with a couple of columns with values way outside of our specified range in telemetry."
  },
  {
    "objectID": "04_different_checks_different_datasets.html#and-writing-automated-reports-to-their-folder",
    "href": "04_different_checks_different_datasets.html#and-writing-automated-reports-to-their-folder",
    "title": "5  Different Checks for Different Datasets",
    "section": "5.10 And Writing Automated Reports to Their Folder",
    "text": "5.10 And Writing Automated Reports to Their Folder\n\n# Start with an empty list of file paths\n\nreport_paths_processed <- list()\n\n# Create the for loop that will create a populated list of file paths\n\nfor (file_name in file_names) {\n  \n  # Create the string needed for the file path using `glue`\n  \n  path_init <- glue(\"reports/processed/{now()}_{file_name}_report.html\")\n  \n  # Create the path itself using `here`\n  # Note, we could do this all at once but it's less readable\n  \n  path <- here::here(path_init)\n  \n  # Append (or add to the end) the current path to the formerly empty list\n  \n  report_paths_processed <- append(report_paths_processed, path)\n  \n}\n\n\n# Commented out here so we don't create a new version of the report during every reload\n\n# map2(all_agents_processed, report_paths_processed, ~export_report(.x, .y))"
  },
  {
    "objectID": "04_different_checks_different_datasets.html#conclusion",
    "href": "04_different_checks_different_datasets.html#conclusion",
    "title": "5  Different Checks for Different Datasets",
    "section": "5.11 Conclusion",
    "text": "5.11 Conclusion\nWe now have all the building blocks necessary to create a scalable, reproducible pipeline with automated checks across all datasets from a single type of source. {pointblank} has a dizzying number of kinds of tests you can perform on your data, and you can learn more from its docs.\nMany organizations will understandably stop here. They get there data from one kind of source10 and will plan to run this pipeline manually whenever a lot of new data comes in. They’ll also add new checks as they go.\n\nHowever, there are still three more advanced topics this resource might cover:\n\nAutomated preprocessing based on failed checks + retesting after that preprocessing\nGetting data from multiple kinds of sources before testing + preprocessing\nAutomatically running your data pipeline on a schedule.\n\nIf there’s massive demand and I have more time than I anticipate, I might:\n\nAdd a case study for data engineering in R\nCreate a companion version of this textbook using Python + SQL to help people bridge their data engineering skills to the far more commonly used tools at larger scales."
  },
  {
    "objectID": "01_initial_pipeline_upgrades.html#still-read-in-raw-data",
    "href": "01_initial_pipeline_upgrades.html#still-read-in-raw-data",
    "title": "2  Initial Pipeline Upgrades",
    "section": "2.3 Still Read in Raw Data",
    "text": "2.3 Still Read in Raw Data\nWe’ll continue our pipeline as in the last chapter by writing our just ingested data to the “raw/” folder in our R Project.\n\noutput_path_improved <- here::here(\"data_from_gsheets/raw/palmer_penguins_improved.csv\")\n\nwrite_csv(penguins_remote_improved, output_path_improved)"
  },
  {
    "objectID": "03_handle_multiple_datasets.html#we-can-automatically-check-our-data-across-many-datasets",
    "href": "03_handle_multiple_datasets.html#we-can-automatically-check-our-data-across-many-datasets",
    "title": "4  Handle Multiple Datasets",
    "section": "4.7 We Can Automatically Check Our Data Across Many Datasets",
    "text": "4.7 We Can Automatically Check Our Data Across Many Datasets\nThere are certain data quality checks we’re going to want to do across all of our datasets. A lack of duplicate IDs is an example of one such check, so let’s start there. Don’t worry if you don’t understand all this code yet, we’re going to dive deep in the next chapter into how it works step by step.\n\n# Need to input the datasets and the name of the id variable for each\n\nid_var_names <- c(\"individual_id\",\"participant_id\", \"id\")\n\nall_agents <- map2(all_datasets_initial, id_var_names, ~{\n  \n  .x %>%\n    create_agent(\n      label = \"Check for unique ids\",\n      actions = action_levels(warn_at = 1)\n    ) %>%\n    rows_distinct(\n      columns = vars(!!!.y)\n    ) %>%\n    interrogate()\n  \n})\n\nall_agents[[3]]\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n      Pointblank Validation\n    \n    \n      Check for unique ids\ntibbleWARN\n1\nSTOP\n—\nNOTIFY\n—\n\n    \n    \n      \n      \n      STEP\n      COLUMNS\n      VALUES\n      TBL\n      EVAL\n      UNITS\n      PASS\n      FAIL\n      W\n      S\n      N\n      EXT\n    \n  \n  \n    \n1\n\n      rows_distinct                                                                                                            \n   rows_distinct()\n\n\n\n  \n    ▮id\n  \n\n\n—\n                                                            \n\n✓\n\n1K\n1K1.00\n00.00\n○\n\n—\n\n—\n\n—\n\n  \n  \n    \n      2023-09-26 16:27:27 MDT\n< 1 s\n2023-09-26 16:27:27 MDT"
  },
  {
    "objectID": "03_handle_multiple_datasets.html#modifying-our-previous-code",
    "href": "03_handle_multiple_datasets.html#modifying-our-previous-code",
    "title": "4  Handle Multiple Datasets",
    "section": "4.3 Modifying Our Previous Code",
    "text": "4.3 Modifying Our Previous Code\n\n# Since this Google Sheet is public to anyone with the link we don't need\n# to authenticate\n\ngs4_deauth()\n\n# Get the IDs of our Google Sheets\n\nsheet_ids <- c(\"1v0lG-4arxF_zCCpfoUzCydwzaea7QqWTTQzTr8Dompw\",\n               \"1wPmFajaVyWIImmvEyf6wp16mAkX1PGC5jyKUx7s7DBQ\",\n               \"1Biy_OhNxkaWDteBQt7AfzD89g1j2NY7mctYr50S2WVg\")\n\n# Read in all the data using the googlesheets4 package\n\nall_datasets_raw <- map(sheet_ids, ~read_sheet(.x, na = \"NA\"))\n\nThere are more complicated, technically correct ways to think about what map() does, but for now:\nmap() lets us write code like we’re doing the process once1, replace the single instance2 with a placeholder .x, and run the code on a bunch of instances3.\nThis is a lot to get our brains around at first, and it’s one of the engines that makes scalable, reproducible data pipelines possible. For a resource focused on helping you understand map() click here"
  },
  {
    "objectID": "03_handle_multiple_datasets.html#add-pre-processing-to-our-multi-dataset-pipeline",
    "href": "03_handle_multiple_datasets.html#add-pre-processing-to-our-multi-dataset-pipeline",
    "title": "4  Handle Multiple Datasets",
    "section": "4.5 Add Pre-Processing to Our Multi-Dataset Pipeline",
    "text": "4.5 Add Pre-Processing to Our Multi-Dataset Pipeline\nLet’s start by using the {janitor} package to clean up our column names across all the datasets, rather than just one. We’ll switch back to map() for this version of “do multiple datasets at once.”\n\nall_datasets_initial <- map(file_names, ~{\n  \n  # Create file name\n  \n  path_for_read <- glue(\"data_from_gsheets/raw/{.x}.csv\")\n  \n  # Read in the csv and clean the column names\n  \n  read_csv(path_for_read) %>%\n    clean_names()\n  \n})"
  }
]